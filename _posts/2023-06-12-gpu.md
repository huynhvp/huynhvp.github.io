---
layout: post
title: Experimental benchmarks on the GPU requirements for the training/fine-tuning of LLMs.
date: 2023-06-12 10:09:00
description: 
tags: dev
categories: language_model, gpu
---

---

This post gathers experimental setups on the GPU usage for the training/fine-tuning of LLMs in the wild.

---

<b>Table of Contents</b>
* TOC []
{:toc}


###### <b>Fine-tuning with DeepSpeed</b>

- My own experience:

    | Model      | Context length | DS Zero offload  | GPU | precision | batch_size_per_GPU | gradient_accumulation | 
    | -----------| ----------- | ----------- | ----------- | ----------- | ----------- | 
    | CodeT5+ 2B     | 1024     | Yes (50G CPU) | 2x A100 40G | bf16 | 1 | 4 | 
    | FLANT5-XL 3B   | 1024      | Yes (50G CPU) | 2x RTX 4090 24G | bf16 | 1 | 4 | 

<br>

- <b>FLAN-XL (3B) + FLAN-XL (11B)</b>

    ![](/assets/img/gpu/ft_deepspeed_flan.png){:style="width: 50%; display:block; margin-left:auto; margin-right:auto"} *(Source: https://www.philschmid.de/fine-tune-flan-t5-deepspeed)*

###### <b>Fine-tuning with FSDP</b>

- My own experience:

    | Model      | Context length | Full_shard   | GPU | precision | batch_size_per_GPU | gradient_accumulation | 
    | -----------| ----------- | ----------- | ----------- | ----------- | ----------- | 
    | Llama-Alpaca 6B     | 512     | Yes | 6x A100 40G | bf16 | 1 | 4 | 

- <b>GPT-2 XL (1.5B)</b>

    2x24GB NVIDIA RTX

    ![](/assets/img/gpu/fsdp_gpt.png){:style="width: 50%; display:block; margin-left:auto; margin-right:auto"} *(Source: https://huggingface.co/blog/pytorch-fsdp)*

###### <b>Fine-tuning with LoRA</b>

- My own experience:

    | Model      | Context length  | GPU | precision | batch_size_per_GPU | gradient_accumulation | 
    | -----------| ----------- | ----------- | ----------- | ----------- | ----------- | 
    | CodeT5+ 2B     | 1024     |  1x RTX 4090 24G | fp16 | 1 | 8 |

<br>

- <b>TO (3B) + mTO (12B) + BLOOMZ (7B) (7B)</b>

    ![](/assets/img/gpu/a100.png){:style="width: 60%; display:block; margin-left:auto; margin-right:auto"} *(Source: https://github.com/huggingface/peft*

